Welcome to My GitHub Profile! 👩‍💻
👋 About Me
Hi, I'm Tanvi Kandepuneni, an aspiring tech professional passionate about combining technology and healthcare to create impactful solutions. I specialize in machine learning, data analysis, and signal processing, with a strong interest in seizure detection and classification using EEG data. My projects reflect my commitment to continuous learning and innovation.

📫 Contact me: kandepuneni24@gmail.com
🔗 LinkedIn: https://www.linkedin.com/in/tanvi-kandepuneni-650711268/

Highlighted projects:

AI Studio MIT-IBM Watson AI lab : Dialogue Decoded: Humans vs LLMs
Project Overview
The Dialogue Decoded project investigates the comparative performance of large and small language models across single-turn and multi-turn prompts, focusing on key topics. Inspired by biological systems' adaptability, the study explores how context retention and simplicity interplay to optimize outcomes, much like organisms adapt and specialize in their environments.

Bio-Inspired Perspective
Contextual Coherence:
Large models mirror the adaptive capacity of biological systems in maintaining coherence over extended interactions (multi-turn prompts), much like how memory and cognition in living beings help in navigating complex environments.

Simplicity vs. Complexity:
Small models demonstrate the efficiency of minimalism in straightforward scenarios (single-turn prompts), drawing parallels with how simpler organisms excel in specific niches.

Adaptation to Domains:
Both large and small models exhibit topic-specific strengths, akin to the specialization of species to specific ecosystems. Large models dominate ambiguous, creative tasks, while small models thrive in structured, factual domains.

Objectives
Analyze how interaction length impacts performance for large and small models.
Derive topic-specific insights, emphasizing biological adaptability principles.
Visualize and summarize the win rates of models across factual and creative topics in both prompt types.
Approach
Model Categorization: Differentiated models based on parameter size:

Large models: >65B parameters.
Small models: ≤65B parameters.
Prompt Filtering: Selected only small vs. large comparisons for meaningful insights.

Prompt Grouping: Segregated prompts into single-turn and multi-turn categories.

Topic Clustering: Applied BERTopic to identify and select 10 key topics out of 34 clusters.

Performance Analysis: Computed win rates, including ties, for large and small models by turn type and topic.

Visualization & Insights: Created graphs and extracted biologically-inspired observations, mirroring specialization in evolution.

